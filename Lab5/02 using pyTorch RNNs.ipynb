{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97cf9568-cd60-4dc6-aaa8-096ee6e0156e",
   "metadata": {},
   "source": [
    "# Using pyTorch implementation\n",
    "\n",
    "In this second part, we use pyTorch's implementation of RNNs and LSTMs. Again, as we are focusing on understanding the model and library, we will keep using the IMDB dataset. The good news is training is much faster using pyTorch's implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc80f0-e4e1-4ba3-bbda-582167fb43dc",
   "metadata": {},
   "source": [
    "## From dataset to batch inputs\n",
    "\n",
    "You already know what to do here, it's the same as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab54493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junyi\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from typing import Callable, Dict, Generator, List, Tuple\n",
    "from collections import Counter, OrderedDict\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchtext.vocab import vocab, Vocab\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9197e158",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/junyi/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 199.99it/s]\n",
      "Loading cached split indices for dataset at C:\\Users\\junyi\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-5f37fd0866e4f89f.arrow and C:\\Users\\junyi\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-dd5732a0e6ac784c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((20000, 2), (5000, 2), (25000, 2))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_dataset = dataset[\"train\"].train_test_split(\n",
    "    stratify_by_column=\"label\", test_size=0.2, seed=42\n",
    ")\n",
    "test_df = dataset[\"test\"]\n",
    "train_df = train_dataset[\"train\"]\n",
    "valid_df = train_dataset[\"test\"]\n",
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc648f3b",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05884c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_token = '<unk>'\n",
    "pad_token = '<pad>'\n",
    "tokenizer = get_tokenizer(\"basic_english\", language=\"en\")\n",
    "corpus = train_df['text']\n",
    "tokens = []\n",
    "for text in corpus:\n",
    "    tokens += tokenizer(text)\n",
    "counter = Counter(tokens)\n",
    "sorted_by_freq_tuples = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocabulary = vocab(ordered_dict, specials=[unk_token, pad_token], min_freq = 5)\n",
    "vocabulary.set_default_index(vocabulary[unk_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4324d",
   "metadata": {},
   "source": [
    "### Vectorize and batch the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ab64b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(\n",
    "    text: str, vocabulary: Vocab, tokenizer: Callable[[str], List[str]]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate a tensor of vocabluary IDs for a given text.\n",
    "    Args:\n",
    "        text: the input text.\n",
    "        vocabulary: a Vocab objects.\n",
    "        tokenizer: a text tokenizer.\n",
    "    Returns:\n",
    "        A tensor of IDs (torch.long).\n",
    "    \"\"\"\n",
    "    tokens = tokenizer(text)\n",
    "\n",
    "    ids = [vocabulary[token] for token in tokens]\n",
    "\n",
    "    tensor = torch.tensor(ids, dtype=torch.long)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72122337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 20000/20000 [00:05<00:00, 3667.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:01<00:00, 3683.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 25000/25000 [00:06<00:00, 3724.33it/s]\n"
     ]
    }
   ],
   "source": [
    "text_pipeline = partial(vectorize_text, vocabulary=vocabulary, tokenizer=tokenizer)\n",
    "X_train = [text_pipeline(text) for text in tqdm(train_df[\"text\"])]\n",
    "y_train = train_df[\"label\"]\n",
    "X_valid = [text_pipeline(text) for text in tqdm(valid_df[\"text\"])]\n",
    "y_valid = valid_df[\"label\"]\n",
    "X_test = [text_pipeline(text) for text in tqdm(test_df[\"text\"])]\n",
    "y_test = test_df[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44bfc12",
   "metadata": {},
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53afd951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(\n",
    "    X: List[torch.tensor], y: List[int], pad_id: int, batch_size: int = 32\n",
    ") -> Generator[Tuple[torch.Tensor, torch.Tensor], None, None]:\n",
    "    \"\"\"\n",
    "    Yield batches from given input data and labels.\n",
    "    Args:\n",
    "        X: a list of tensor (input features).\n",
    "        y: the corresponding labels.\n",
    "        batch_size: the size of every batch [32].\n",
    "    Returns:\n",
    "        A tuple of tensors (features, labels).\n",
    "    \"\"\"\n",
    "    X, y = shuffle(X, y)\n",
    "    n_batches = len(X) // batch_size\n",
    "    if len(X) % batch_size != 0:\n",
    "        n_batches += 1\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "        batch_X = X[start_idx:end_idx]\n",
    "        batch_y = y[start_idx:end_idx]\n",
    "\n",
    "        # Padding the batch_X to the length of the longest element\n",
    "        max_length = max([len(x) for x in batch_X])\n",
    "        padded_X = []\n",
    "        for x in batch_X:\n",
    "            padding_length = max_length - len(x)\n",
    "            padded_x = torch.nn.functional.pad(x, (0, padding_length), value=pad_id)\n",
    "            padded_X.append(padded_x)\n",
    "        \n",
    "        yield torch.stack(padded_X), torch.tensor(batch_y)\n",
    "\n",
    "train_gen = lambda: data_generator(X_train, y_train, vocabulary[pad_token])\n",
    "valid_gen = lambda: data_generator(X_valid, y_valid, vocabulary[pad_token])\n",
    "test_gen = lambda: data_generator(X_test, y_test, vocabulary[pad_token])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cecf52-8386-4dc1-9600-0f03554fe082",
   "metadata": {},
   "source": [
    "## The classifier\n",
    "\n",
    "The implementation behind shows how to use the [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) implementation provided by pyTorch to code a simple RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4e78187-f53f-42b9-92c1-b94d23f9d28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \"\"\"A simple RNN module with word embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_size: int, hidden_size: int, n_layers: int, n_outputs: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: vocabulary size.\n",
    "            embed_size: embedding dimensions.\n",
    "            hidden_size: hidden layer size.\n",
    "            n_layers: the number of layers.\n",
    "            n_outputs: the number of output classes.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "\n",
    "        # The word embedding layer.\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        # The RNN\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size = self.embed_size,\n",
    "            hidden_size = self.hidden_size,\n",
    "            num_layers = self.n_layers,\n",
    "            batch_first = True, # Changes the order of dimension to put the batches first.\n",
    "        )\n",
    "        # A fully connected layer to project the RNN's output to only one output used for classification.\n",
    "        self.fc = nn.Linear(self.hidden_size, self.n_outputs)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function called when the model is called with data as input.\n",
    "        Args:\n",
    "            X: the input tensor of dimensions batch_size, sequence length, vocab size (actually just an int).\n",
    "        Returns:\n",
    "            The resulting tensor of dimension batch_size, sequence length, output dimensions.\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.n_layers, X.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out = self.embed(X)\n",
    "        # out contains the output layer of all words in the sequence.\n",
    "        # First dim is batch, second the word in the sequence, third is the vector itself.\n",
    "        # The second output value is the last vector of all intermediate layer.\n",
    "        # Only use it if you want to access the intermediate layer values of a\n",
    "        # multilayer model.\n",
    "        out, _ = self.rnn(out, h0)\n",
    "        # Getting the last value only.\n",
    "        out = out[:, -1, :]\n",
    "    \n",
    "        # Linear projection.\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcacae71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c590a0c-69f0-48b5-9336-f7f33df481af",
   "metadata": {},
   "source": [
    "## Training (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17a3c8-640d-41bd-be8d-8976e935a274",
   "metadata": {},
   "source": [
    "**\\[1 point\\]** Code the training function.\n",
    "* Note that we are using a function, as we will use it on several models here.\n",
    "* The RNN implementation of pyTorch doesn't need to be manually looped. As commented in the `forward` function above, `out` contains the ouptut layer for all words in the sequence, and taking its last value is what we needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528c1bf6-386d-4db4-9c85-001bd3379568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    criterion: Callable,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    n_epochs: int,\n",
    "    train_gen: Callable,\n",
    "    valid_gen: Callable,\n",
    ") -> Tuple[nn.Module, List[float], List[float]]:\n",
    "    \"\"\"Train a model using batch gradient descent.\n",
    "    Args:\n",
    "        model: a class inheriting from nn.Module.\n",
    "        criterion: a loss criterion.\n",
    "        optimizer: an optimizer (e.g. Adam, RMSprop, ...).\n",
    "        n_epochs: the number of training epochs.\n",
    "        train_gen: a callable function returning a batch (data, labels).\n",
    "        valid_gen: a callable function returning a batch (data, labels).\n",
    "    Returns:\n",
    "        A tuple: [best_model (by validation loss), training losses, validation losses].\n",
    "    \"\"\"\n",
    "    best_loss = float('inf')\n",
    "    best_model = None\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for X_train_batch, y_train_batch in train_gen():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(X_train_batch).squeeze(-1)\n",
    "            target = y_train_batch.float()\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= sum(1 for _ in train_gen())\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X_valid_batch, y_valid_batch in valid_gen():\n",
    "                output = model(X_valid_batch).squeeze(-1)\n",
    "                target = y_valid_batch.float()\n",
    "                loss = criterion(output, target)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "\n",
    "        valid_loss /= sum(1 for _ in valid_gen())\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{n_epochs} - Train Loss: {train_loss:.4f} - Valid Loss: {valid_loss:.4f}\")\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model = copy.deepcopy(model)\n",
    "\n",
    "    return best_model, train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab8bdab-8072-45e5-a1d8-90041fa49936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(len(vocabulary), 32, 64, 1, 1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32881f1e-f71f-463e-8f86-b0b6a16bd919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train Loss: 0.6951 - Valid Loss: 0.6931\n"
     ]
    }
   ],
   "source": [
    "best_model, train_losses, valid_losses = train(model, criterion, optimizer, 1, train_gen, valid_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87db1d40-187a-40cd-a940-89a1af1e6b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a729d174c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(valid_losses, label=\"Validation loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf154e66-6ba3-411e-80c9-6b0eebf122e3",
   "metadata": {},
   "source": [
    "## Do the following (5 points)\n",
    "* **\\[1 point\\]** Add an accuracy function and report the accuracy of the training, validation, and test set.\n",
    "* **\\[2 points\\]** Create an LSTM class which uses an LSTM instead of an RNN. Compare its results with the RNN.\n",
    "  * Look at the [LSTM documentation of pyTorch](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html).\n",
    "* **\\[1 point\\]** Implement a function which takes any text and returns the model's prediction.\n",
    "    * The function should have a string as input and return a class (0 or 1) and its confidence (between 0 and 1).\n",
    "* **\\[Bonus\\]** Create a bidirectional LSTM (BiLSTM) class to classify your sentences. Report the accuracy on the training and test data.\n",
    "    * **Beware of the behaviour of the output layer.** For a bidirectional LSTM, the output layer concatenates the forward and backward vector of each token. But we need to use the forward output of the last token, and the backward output of the first token, as input to our output layer.\n",
    "* **\\[1 point\\]** With your best classifier, look at two wrongly classified examples on the test set. Try explaining why the model was wrong.\n",
    "* **\\[Bonus\\]** Try finding better hyperparameters (dimensions, number of layers, ...). Document your experiments and results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c20aba",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "220166c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 50.03%\n",
      "Valid Accuracy: 49.72%\n",
      "Test Accuracy: 49.90%\n"
     ]
    }
   ],
   "source": [
    "def compute_accuracy(model: nn.Module, data_gen: Callable) -> float:\n",
    "    \"\"\"Compute the accuracy of the model on a given dataset.\n",
    "    Args:\n",
    "        model: a trained model.\n",
    "        data_gen: a callable function returning a batch (data, labels).\n",
    "    Returns:\n",
    "        The accuracy of the model on the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_gen():\n",
    "            output = model(X_batch)\n",
    "            predictions = torch.round(torch.sigmoid(output))  # Apply threshold at 0.5 for binary classification\n",
    "            correct += (predictions.squeeze() == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "train_accuracy = compute_accuracy(best_model, train_gen)\n",
    "valid_accuracy = compute_accuracy(best_model, valid_gen)\n",
    "test_accuracy = compute_accuracy(best_model, test_gen)\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Valid Accuracy: {valid_accuracy:.2%}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec85aa0-2afa-4007-b68c-b8359addc1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.50035\n",
      "Validation accuracy: 0.4968\n",
      "Test accuracy: 0.49892\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "best_model.eval()\n",
    "train_preds = []\n",
    "train_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in train_gen():\n",
    "        output = best_model(X).squeeze(-1)\n",
    "        preds = torch.round(torch.sigmoid(output))\n",
    "        train_preds.extend(preds)\n",
    "        train_targets.extend(y)\n",
    "\n",
    "train_acc = accuracy_score(train_targets, train_preds)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "best_model.eval()\n",
    "valid_preds = []\n",
    "valid_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in valid_gen():\n",
    "        output = best_model(X).squeeze(-1)\n",
    "        preds = torch.round(torch.sigmoid(output))\n",
    "        valid_preds.extend(preds)\n",
    "        valid_targets.extend(y)\n",
    "\n",
    "valid_acc = accuracy_score(valid_targets, valid_preds)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "best_model.eval()\n",
    "test_preds = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_gen():\n",
    "        output = best_model(X).squeeze(-1)\n",
    "        preds = torch.round(torch.sigmoid(output))\n",
    "        test_preds.extend(preds)\n",
    "        test_targets.extend(y)\n",
    "\n",
    "test_acc = accuracy_score(test_targets, test_preds)\n",
    "\n",
    "print(f\"Training accuracy: {train_acc}\")\n",
    "print(f\"Validation accuracy: {valid_acc}\")\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c3f0b",
   "metadata": {},
   "source": [
    "The accuracies are at 50% which means that a problem has occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66794794",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \"\"\"A simple LSTM module with word embeddings.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size: int, embed_size: int, hidden_size: int, n_layers: int, n_outputs: int) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vocab_size: vocabulary size.\n",
    "            embed_size: embedding dimensions.\n",
    "            hidden_size: hidden layer size.\n",
    "            n_layers: the number of layers.\n",
    "            n_outputs: the number of output classes.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.n_outputs = n_outputs\n",
    "\n",
    "        # The word embedding layer.\n",
    "        self.embed = nn.Embedding(self.vocab_size, self.embed_size)\n",
    "        # The LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.embed_size,\n",
    "            hidden_size=self.hidden_size,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        # A fully connected layer to project the LSTM's output to the output dimension for classification.\n",
    "        self.fc = nn.Linear(self.hidden_size, self.n_outputs)\n",
    "\n",
    "    def forward(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Function called when the model is called with data as input.\n",
    "        Args:\n",
    "            X: the input tensor of dimensions batch_size, sequence length, vocab size (actually just an int).\n",
    "        Returns:\n",
    "            The resulting tensor of dimension batch_size, sequence length, output dimensions.\n",
    "        \"\"\"\n",
    "        h0 = torch.zeros(self.n_layers, X.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.n_layers, X.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out = self.embed(X)\n",
    "        out, _ = self.lstm(out, (h0, c0))\n",
    "        out = out[:, -1, :]\n",
    "\n",
    "        # Linear projection.\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd5ae4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 - Train Loss: 0.6939 - Valid Loss: 0.6939\n",
      "LSTM Train Accuracy: 0.50%\n",
      "LSTM Valid Accuracy: 0.50%\n",
      "LSTM Test Accuracy: 0.50%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the LSTM model\n",
    "lstm_model = LSTM(len(vocabulary), 32, 64, 1, 1).to(device)\n",
    "\n",
    "# Train the LSTM model\n",
    "lstm_best_model, lstm_train_losses, lstm_valid_losses = train(lstm_model, criterion, optimizer, 1, train_gen, valid_gen)\n",
    "\n",
    "# Compute accuracies for the LSTM model\n",
    "lstm_train_accuracy = compute_accuracy(lstm_best_model, train_gen)\n",
    "lstm_valid_accuracy = compute_accuracy(lstm_best_model, valid_gen)\n",
    "lstm_test_accuracy = compute_accuracy(lstm_best_model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "efeec770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Train Accuracy: 50.04%\n",
      "LSTM Valid Accuracy: 50.42%\n",
      "LSTM Test Accuracy: 49.94%\n"
     ]
    }
   ],
   "source": [
    "print(f\"LSTM Train Accuracy: {lstm_train_accuracy:.2%}\")\n",
    "print(f\"LSTM Valid Accuracy: {lstm_valid_accuracy:.2%}\")\n",
    "print(f\"LSTM Test Accuracy: {lstm_test_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60bf0ea",
   "metadata": {},
   "source": [
    "Same here, we have accuracies at 50%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
