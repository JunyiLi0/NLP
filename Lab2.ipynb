{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3575df53",
   "metadata": {},
   "source": [
    "# Lab 02\n",
    "## Introduction\n",
    "This project's goal is to code a sentiment classifier on the IMDB sentiment dataset. The IMDB sentiment [dataset](https://huggingface.co/datasets/imdb) is a collection of 50K movie reviews, annotated as positive or negative, and split in two sets of equal size: a training and a test set. Both set have an equal number of positive and negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ccd6f",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a164ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27bede",
   "metadata": {},
   "source": [
    "1. How many splits does the dataset has ?\n",
    "2. How big are these splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6f4f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45688a96",
   "metadata": {},
   "source": [
    "The dataset has 3 splits : train, test and unsupervised. They represent respectively 25000, 25000 and 50000 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7f63e",
   "metadata": {},
   "source": [
    "3. What is the proportion of each class on the supervised splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4a8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "positiveTrain = dataset['train'].filter(lambda example: example['label'] == 1).num_rows\n",
    "positiveTest = dataset['test'].filter(lambda example: example['label'] == 1).num_rows\n",
    "print(\"In the train and test splits, there are respectively \"+ str(positiveTrain) + \"/25000 and \" + str(positiveTest) + \"/25000 positive ratings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fa35e",
   "metadata": {},
   "source": [
    "Both supervised  have an equal number of positive and negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c616bc",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "### 1. Processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def process(txt):\n",
    "    \"\"\"\n",
    "    Converts all uppercase letters to lowercase, replaces all punctuation marks with spaces, and returns the processed string.\n",
    "    \"\"\"\n",
    "    \n",
    "    lowercase_txt = txt.lower()\n",
    "    \n",
    "    # create a translation table using maketrans method\n",
    "    replace_punctuation = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    # use the translate method to replace the punctuation\n",
    "    processed_txt = lowercase_txt.translate(replace_punctuation)\n",
    "    return processed_txt\n",
    "process(\"What's your name? I'm Ba-yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d36eff",
   "metadata": {},
   "source": [
    "### 2. Our Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "\n",
    "def train_naive_bayes(documents, classes):\n",
    "    #def train_naive_bayes(documents: list[str], classes: list[int]) -> tuple[set[int, float], set[tuple[str, int], float], list[str]]:\n",
    "    \"\"\"\n",
    "    Trains a Naive Bayes classifier on a list of labeled documents.\n",
    "\n",
    "    Args:\n",
    "    - documents (list): A list of dictionaries containing the text and label for each document.\n",
    "    - classes (list): A list of the possible class labels (0 or/and 1).\n",
    "\n",
    "    Returns:\n",
    "    - log_prior (dict): A dictionary containing the log prior probabilities for each class.\n",
    "    - log_likelihood (dict): A defaultdict containing the log likelihood probabilities\n",
    "    for each word in the vocabulary given each class.\n",
    "    - vocabulary (set): A set of words in the vocabulary.\n",
    "    - class_word_sets (dict): a dictionary containing sets of words in each class.\n",
    "    \"\"\"\n",
    "    n_doc = len(documents)\n",
    "    log_prior = {}\n",
    "    whole_vocabulary = set([word for d in documents for word in process(d['text']).split()])\n",
    "    vocabulary = sorted({s for s in whole_vocabulary if s.isalpha()})\n",
    "    log_likelihood = defaultdict(lambda: math.log(1/len(vocabulary)))\n",
    "    bigdoc = {}\n",
    "    word_counts = {}\n",
    "    class_word_sets = {}\n",
    "    # Calculate P(c) terms\n",
    "    for c in classes:\n",
    "        n_c = len([d for d in documents if d['label'] == c])\n",
    "        log_prior[c] = math.log(n_c / n_doc)\n",
    "\n",
    "    # Calculate P(w|c) terms\n",
    "        bigdoc = [process(d['text']).split() for d in documents if d['label'] == c]\n",
    "        word_counts[c] = Counter([word for doc in bigdoc for word in doc])\n",
    "        class_word_sets[c] = set(word_counts[c].keys())\n",
    "        total_count = sum(word_counts[c].values())\n",
    "        for word in vocabulary:\n",
    "            count_w_c = word_counts[c][word]\n",
    "            log_likelihood[(word, c)] = math.log((count_w_c + 1) / (total_count + len(vocabulary)))\n",
    "\n",
    "    return log_prior, log_likelihood, vocabulary, class_word_sets\n",
    "\n",
    "\n",
    "def test_naive_bayes(test_txt, log_prior, log_likelihood, classes, vocabulary, class_word_sets):\n",
    "    \"\"\"\n",
    "    Predicts the label of a given test document using a trained Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "    # Calculate sum[c] for each class c\n",
    "    sum_c = {}\n",
    "    test_words = set(test_txt.split())\n",
    "    for c in classes:\n",
    "        if test_words & class_word_sets[c]:\n",
    "            sum_c[c] = log_prior[c]\n",
    "            for word in test_words & class_word_sets[c]:\n",
    "                sum_c[c] += log_likelihood[(word, c)]\n",
    "    \n",
    "    # Return the class with highest sum[c]\n",
    "    return max(sum_c, key=sum_c.get)\n",
    "\n",
    "def test_accuracy(test_set, log_prior, log_likelihood, classes, vocabulary, class_word_sets):\n",
    "    \"\"\"\n",
    "    Tests the accuracy of a trained Naive Bayes classifier on a given test set.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy of the classifier on the test set as a fraction between 0 and 1.\n",
    "    \"\"\"\n",
    "    true = 0\n",
    "    total = 0\n",
    "    for test_doc in test_set:\n",
    "        test_class = test_naive_bayes(process(test_doc[\"text\"]), log_prior, log_likelihood, classes, vocabulary, class_word_sets)\n",
    "        if test_doc[\"label\"] == test_class:\n",
    "            true += 1\n",
    "        total += 1\n",
    "    return true/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484b66f",
   "metadata": {},
   "source": [
    "### 3. With Sickit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e160b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),  # Vectorize the data\n",
    "    ('clf', MultinomialNB()),  # Train  the classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e9b2e",
   "metadata": {},
   "source": [
    "### 4. Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f7708",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d08e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior, log_likelihood, vocabulary, class_word_sets = train_naive_bayes(dataset['train'], [0, 1])\n",
    "text_clf.fit(dataset['train']['text'], dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d4d6b9",
   "metadata": {},
   "source": [
    "#### Testing Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdbad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sickit_test = text_clf.score(dataset['test']['text'], dataset['test']['label'])\n",
    "sickit_train = text_clf.score(dataset['train']['text'], dataset['test']['label'])\n",
    "print(\"The accuracy on both training and test set, for the scikit-learn implementation are respectively \" + str(sickit_train) +\n",
    "      ' and ' + str(sickit_test))\n",
    "ours_train = test_accuracy(dataset['train'], log_prior, log_likelihood, [0, 1], vocabulary, class_word_sets)\n",
    "ours_test = test_accuracy(dataset['test'], log_prior, log_likelihood, [0, 1], vocabulary, class_word_sets)\n",
    "print(\"The accuracy on both training and test set, for ours are respectively \" + str(ours_train) + ' and ' + str(ours_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
