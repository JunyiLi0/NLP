{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3575df53",
   "metadata": {},
   "source": [
    "# Lab 02\n",
    "## Introduction\n",
    "This project's goal is to code a sentiment classifier on the IMDB sentiment dataset. The IMDB sentiment [dataset](https://huggingface.co/datasets/imdb) is a collection of 50K movie reviews, annotated as positive or negative, and split in two sets of equal size: a training and a test set. Both set have an equal number of positive and negative review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7ccd6f",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83a164ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5560\\2805881029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"imdb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27bede",
   "metadata": {},
   "source": [
    "1. How many splits does the dataset has ?\n",
    "2. How big are these splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6f4f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 25000, 'test': 25000, 'unsupervised': 50000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45688a96",
   "metadata": {},
   "source": [
    "The dataset has 3 splits : train, test and unsupervised. They represent respectively 25000, 25000 and 50000 examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e7f63e",
   "metadata": {},
   "source": [
    "3. What is the proportion of each class on the supervised splits ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d4a8c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\antho\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-50ca35f45cb9d15a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\antho\\.cache\\huggingface\\datasets\\imdb\\plain_text\\1.0.0\\d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0\\cache-3cd99f281cbb7e3f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the train and test splits, there are respectively 12500/25000 and 12500/25000 positive ratings\n"
     ]
    }
   ],
   "source": [
    "positiveTrain = dataset['train'].filter(lambda example: example['label'] == 1).num_rows\n",
    "positiveTest = dataset['test'].filter(lambda example: example['label'] == 1).num_rows\n",
    "print(\"In the train and test splits, there are respectively \"+ str(positiveTrain) + \"/25000 and \" + str(positiveTest) + \"/25000 positive ratings\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4fa35e",
   "metadata": {},
   "source": [
    "Both supervised  have an equal number of positive and negative review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c616bc",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier\n",
    "### 1. Processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d21edaa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what s your name  i m ba yes'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def process(txt):\n",
    "    \"\"\"\n",
    "    Converts all uppercase letters to lowercase, replaces all punctuation marks with spaces, and returns the processed string.\n",
    "    \"\"\"\n",
    "    \n",
    "    lowercase_txt = txt.lower()\n",
    "    \n",
    "    # create a translation table using maketrans method\n",
    "    replace_punctuation = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    # use the translate method to replace the punctuation\n",
    "    processed_txt = lowercase_txt.translate(replace_punctuation)\n",
    "    return processed_txt\n",
    "process(\"What's your name? I'm Ba-yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d36eff",
   "metadata": {},
   "source": [
    "### 2. Our Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f98a01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import math\n",
    "\n",
    "def train_naive_bayes(documents, classes):\n",
    "    #def train_naive_bayes(documents: list[str], classes: list[int]) -> tuple[set[int, float], set[tuple[str, int], float], list[str]]:\n",
    "    \"\"\"\n",
    "    Trains a Naive Bayes classifier on a list of labeled documents.\n",
    "\n",
    "    Args:\n",
    "    - documents (list): A list of dictionaries containing the text and label for each document.\n",
    "    - classes (list): A list of the possible class labels (0 or/and 1).\n",
    "\n",
    "    Returns:\n",
    "    - log_prior (dict): A dictionary containing the log prior probabilities for each class.\n",
    "    - log_likelihood (defaultdict): A defaultdict containing the log likelihood probabilities\n",
    "    for each word in the vocabulary given each class.\n",
    "    - vocabulary (list): A list of words in the vocabulary.\n",
    "    \"\"\"\n",
    "    n_doc = len(documents)\n",
    "    log_prior = {}\n",
    "    whole_vocabulary = set([word for d in documents for word in process(d['text']).split()])\n",
    "    vocabulary = sorted({s for s in whole_vocabulary if s.isalpha()})\n",
    "    log_likelihood = defaultdict(lambda: math.log(1/len(vocabulary)))\n",
    "    bigdoc = {}\n",
    "    word_counts = {}\n",
    "    # Calculate P(c) terms\n",
    "    for c in classes:\n",
    "        n_c = len([d for d in documents if d['label'] == c])\n",
    "        log_prior[c] = math.log(n_c / n_doc)\n",
    "\n",
    "    # Calculate P(w|c) terms\n",
    "        bigdoc = [process(d['text']).split() for d in documents if d['label'] == c]\n",
    "        word_counts[c] = Counter([word for doc in bigdoc for word in doc])\n",
    "        total_count = sum(word_counts[c].values())\n",
    "        for word in vocabulary:\n",
    "            count_w_c = word_counts[c][word]\n",
    "            log_likelihood[(word, c)] = math.log((count_w_c + 1) / (total_count + len(vocabulary)))\n",
    "\n",
    "    return log_prior, log_likelihood, vocabulary\n",
    "\n",
    "\n",
    "def test_naive_bayes(test_txt, log_prior, log_likelihood, classes, vocabulary):\n",
    "    \"\"\"\n",
    "    Predicts the label of a given test document using a trained Naive Bayes classifier.\n",
    "    \"\"\"\n",
    "    # Calculate sum[c] for each class c\n",
    "    sum_c = {}\n",
    "    test_words = set(test_txt.split())\n",
    "    for c in classes:\n",
    "        sum_c[c] = log_prior[c]\n",
    "    for word, c in log_likelihood.keys():\n",
    "        if word in test_words:\n",
    "            sum_c[c] += log_likelihood[(word, c)]\n",
    "    \n",
    "    # Return the class with highest sum[c]\n",
    "    return max(sum_c, key=sum_c.get)\n",
    "\n",
    "def test_accuracy(test_set, log_prior, log_likelihood, classes, vocabulary):\n",
    "    \"\"\"\n",
    "    Tests the accuracy of a trained Naive Bayes classifier on a given test set.\n",
    "\n",
    "    Returns:\n",
    "    - accuracy: The accuracy of the classifier on the test set as a fraction between 0 and 1.\n",
    "    \"\"\"\n",
    "    true = 0\n",
    "    total = 0\n",
    "    for test_doc in test_set:\n",
    "        test_class = test_naive_bayes(process(test_doc[\"text\"]), log_prior, log_likelihood, [0, 1], vocabulary)\n",
    "        if test_doc[\"label\"] == test_class:\n",
    "            true += 1\n",
    "        total += 1\n",
    "    return true/total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6484b66f",
   "metadata": {},
   "source": [
    "### 3. With Sickit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e160b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),  # Vectorize the data\n",
    "    ('clf', MultinomialNB()),  # Train  the classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e9b2e",
   "metadata": {},
   "source": [
    "### 4. Compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019f7708",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67d08e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5560\\3837778612.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlittle_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlittle_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_shards\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlog_prior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_naive_bayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "little_train = dataset['train'].shard(num_shards=100, index=0)\n",
    "little_test = dataset['test'].shard(num_shards=100, index=0)\n",
    "log_prior, log_likelihood, vocabulary = train_naive_bayes(dataset['train'], [0, 1])\n",
    "text_clf.fit(dataset['train']['text'], dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9fbdbad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy(little_test, log_prior, log_likelihood, [0, 1], vocabulary))\n",
    "print(text_clf.score(little_test['text'], little_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8dfab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
