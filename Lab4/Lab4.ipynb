{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17180c27",
   "metadata": {},
   "source": [
    "# Lab 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb8ae364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f38aa",
   "metadata": {},
   "source": [
    "### Turn the dataset into a dataset compatible with FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cb65bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'what s your name  i m ba yes'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "def process(txt: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts all uppercase letters to lowercase, replaces all punctuation marks with spaces, and returns the processed string.\n",
    "    \"\"\"\n",
    "    \n",
    "    lowercase_txt = txt.lower()\n",
    "    txt.replace('<br>', ' ').replace('\\n', ' ').strip()\n",
    "    # create a translation table using maketrans method\n",
    "    replace_punctuation = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    \n",
    "    # use the translate method to replace the punctuation\n",
    "    processed_txt = lowercase_txt.translate(replace_punctuation)\n",
    "    return processed_txt\n",
    "process(\"What's your name? I'm Ba-yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e26283",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (C:/Users/antho/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e7c3156ad64329848d373b4cb73f8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__label__negative after sitting through this pile of dung  my husband and i wondered whether it was actually the product of an experiment to see whether a computer program could produce a movie  it was that listless and formulaic  but the u s  propaganda thrown in your face throughout the film proves  disappointingly  that it s the work of humans  call me a conspiracy theorist  but quotes like   we have to steal the declaration of independence to protect it  seem like ways to justify actions like the invasion of iraq  etc  the fact that nicholas cage spews lines like   i would never use the declaration of independence as a bargaining chip  with a straight face made me and my husband wonder whether the entire cast took valium before shooting each scene  the  reasoning  behind each plot turn and new  clue  is truly ridiculous and impossible to follow  and there s also a bonus side plot of misogyny  with dr  whatever her name was being chided by all involved for  never shutting up   she s clearly in the movie only for looks  but they felt the need to slap a  dr   title on her character to give her some gravity  at one point  cage s character says   don t you ever shut up   and the camera pans to her looking poutily down at her hands  like she s a child  truly grotesque  the only benefit to this movie was that it s so astonishingly bad  you do get a few laughs out of it  the really scary thing is that a majority of the people watching the movie with us seemed to enjoy it  creepy    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "with open('train.txt', 'w', encoding='utf-8') as f:\n",
    "    for example in dataset['train'].shuffle():\n",
    "        text = example['text']\n",
    "        label = '__label__' + ('positive' if example['label'] else 'negative')\n",
    "        f.write(label + ' ' + process(text) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "with open('test.txt', 'w', encoding='utf-8') as f:\n",
    "    for example in dataset['test'].shuffle():\n",
    "        text = example['text']\n",
    "        label = '__label__' + ('positive' if example['label'] else 'negative')\n",
    "        f.write(label + ' ' + process(text) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "with open('train.txt', 'r') as f:\n",
    "    first_line = f.readline()\n",
    "    print(first_line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5ca21",
   "metadata": {},
   "source": [
    "### Train a FastText classifier with default parameters on the training data, and evaluate it on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d717c02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised(input=\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd6b75e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87852"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = model.predict(list(map(process, dataset['test']['text'])))\n",
    "pred_labels = []\n",
    "for pred in preds:\n",
    "    if pred == ['__label__negative']:\n",
    "        pred_labels.append(0)\n",
    "    else:\n",
    "        pred_labels.append(1)\n",
    "accuracy = np.mean(np.array([dataset['test']['label']]) == np.array(pred_labels))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a262b",
   "metadata": {},
   "source": [
    "We reach an accuracy of 0.87852 on our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d1e071",
   "metadata": {},
   "source": [
    "### Use the hyperparameters search functionality of FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbc38f1",
   "metadata": {},
   "source": [
    "#### Split the training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e2011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train'].shuffle()\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    train_dataset['text'],\n",
    "    train_dataset['label'],\n",
    "    test_size=0.2,\n",
    "    stratify=train_dataset['label'],\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "with open('train.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range (len(X_train)):\n",
    "        text = X_train[i]\n",
    "        label = '__label__' + ('positive' if y_train[i] else 'negative')\n",
    "        f.write(label + ' ' + process(text) + '\\n')\n",
    "\n",
    "f.close()\n",
    "\n",
    "with open('valid.txt', 'w', encoding='utf-8') as f:\n",
    "    for i in range (len(X_valid)):\n",
    "        text = X_valid[i]\n",
    "        label = '__label__' + ('positive' if y_valid[i] else 'negative')\n",
    "        f.write(label + ' ' + process(text) + '\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42473dfb",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d81d97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = fasttext.train_supervised(input='train.txt', autotuneValidationFile='valid.txt', verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722f782",
   "metadata": {},
   "source": [
    "Progress: 100.0% Trials:   22 Best score:  0.905800"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a632bf4",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbc21986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89704"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, _ = new_model.predict(list(map(process, dataset['test']['text'])))\n",
    "pred_labels = []\n",
    "for pred in preds:\n",
    "    if pred == ['__label__negative']:\n",
    "        pred_labels.append(0)\n",
    "    else:\n",
    "        pred_labels.append(1)\n",
    "accuracy = np.mean(np.array([dataset['test']['label']]) == np.array(pred_labels))\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef598d",
   "metadata": {},
   "source": [
    "We reach an accuracy of 0.89704 on the obtained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f64590",
   "metadata": {},
   "source": [
    "#### Default parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101e09d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotuneDuration -> 300\n",
      "autotuneMetric -> f1\n",
      "autotuneModelSize -> \n",
      "autotunePredictions -> 1\n",
      "autotuneValidationFile -> \n",
      "bucket -> 0\n",
      "cutoff -> 0\n",
      "dim -> 100\n",
      "dsub -> 2\n",
      "epoch -> 5\n",
      "input -> train.txt\n",
      "label -> __label__\n",
      "loss -> loss_name.softmax\n",
      "lr -> 0.1\n",
      "lrUpdateRate -> 100\n",
      "maxn -> 0\n",
      "minCount -> 1\n",
      "minCountLabel -> 0\n",
      "minn -> 0\n",
      "model -> model_name.supervised\n",
      "neg -> 5\n",
      "output -> \n",
      "pretrainedVectors -> \n",
      "qnorm -> False\n",
      "qout -> False\n",
      "retrain -> False\n",
      "saveOutput -> False\n",
      "seed -> 0\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x000001B1BFDF15B0>>\n",
      "t -> 0.0001\n",
      "thread -> 15\n",
      "verbose -> 2\n",
      "wordNgrams -> 1\n",
      "ws -> 5\n"
     ]
    }
   ],
   "source": [
    "args_obj1 = model.f.getArgs()\n",
    "for hparam in dir(args_obj1):\n",
    "    if not hparam.startswith('__'):\n",
    "        print(f\"{hparam} -> {getattr(args_obj1, hparam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebdc55d",
   "metadata": {},
   "source": [
    "#### Optimized parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd1ac41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotuneDuration -> 300\n",
      "autotuneMetric -> f1\n",
      "autotuneModelSize -> \n",
      "autotunePredictions -> 1\n",
      "autotuneValidationFile -> valid.txt\n",
      "bucket -> 8123144\n",
      "cutoff -> 0\n",
      "dim -> 6\n",
      "dsub -> 2\n",
      "epoch -> 100\n",
      "input -> train.txt\n",
      "label -> __label__\n",
      "loss -> loss_name.softmax\n",
      "lr -> 0.06167811076637881\n",
      "lrUpdateRate -> 100\n",
      "maxn -> 0\n",
      "minCount -> 1\n",
      "minCountLabel -> 0\n",
      "minn -> 0\n",
      "model -> model_name.supervised\n",
      "neg -> 5\n",
      "output -> \n",
      "pretrainedVectors -> \n",
      "qnorm -> False\n",
      "qout -> False\n",
      "retrain -> False\n",
      "saveOutput -> False\n",
      "seed -> 0\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x000001B1B7C9A830>>\n",
      "t -> 0.0001\n",
      "thread -> 15\n",
      "verbose -> 2\n",
      "wordNgrams -> 3\n",
      "ws -> 5\n"
     ]
    }
   ],
   "source": [
    "args_obj2 = new_model.f.getArgs()\n",
    "for hparam in dir(args_obj2):\n",
    "    if not hparam.startswith('__'):\n",
    "        print(f\"{hparam} -> {getattr(args_obj2, hparam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcfa1c6",
   "metadata": {},
   "source": [
    "#### Parameters that changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64109285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autotuneValidationFile -> valid.txt\n",
      "bucket -> 8123144\n",
      "dim -> 6\n",
      "epoch -> 100\n",
      "lr -> 0.06167811076637881\n",
      "setManual -> <bound method PyCapsule.setManual of <fasttext_pybind.args object at 0x000001B1B7C9A830>>\n",
      "wordNgrams -> 3\n"
     ]
    }
   ],
   "source": [
    "for hparam in dir(args_obj2):\n",
    "    if not hparam.startswith('__') and getattr(args_obj2, hparam) != getattr(args_obj1, hparam):\n",
    "        print(f\"{hparam} -> {getattr(args_obj2, hparam)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06253c0",
   "metadata": {},
   "source": [
    "Most important changes are:   \n",
    "dim: size of word vectors 100 -> 6  \n",
    "number of epochs 5 -> 10  \n",
    "learning rate: 0.1 -> 0.62  \n",
    "max length of word ngram 1 -> 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0b7102-fb1d-4a27-a400-ff0e40e1a685",
   "metadata": {},
   "source": [
    "### Two wrongly classified samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "848f856a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First off let me say, If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie. Most of these movies may not have the best plots or best actors but I enjoy these kinds of movies for what they are. This movie is much better than any of the movies the other action guys (Segal and Dolph) have thought about putting out the past few years. Van Damme is good in the movie, the movie is only worth watching to Van Damme fans. It is not as good as Wake of Death (which i highly recommend to anyone of likes Van Damme) or In hell but, in my opinion it's worth watching. It has the same type of feel to it as Nowhere to Run. Good fun stuff!\n",
      "0 1\n",
      "Ben, (Rupert Grint), is a deeply unhappy adolescent, the son of his unhappily married parents. His father, (Nicholas Farrell), is a vicar and his mother, (Laura Linney), is ... well, let's just say she's a somewhat hypocritical soldier in Jesus' army. It's only when he takes a summer job as an assistant to a foul-mouthed, eccentric, once-famous and now-forgotten actress Evie Walton, (Julie Walters), that he finally finds himself in true 'Harold and Maude' fashion. Of course, Evie is deeply unhappy herself and it's only when these two sad sacks find each other that they can put their mutual misery aside and hit the road to happiness.<br /><br />Of course it's corny and sentimental and very predictable but it has a hard side to it, too and Walters, who could sleep-walk her way through this sort of thing if she wanted, is excellent. It's when she puts the craziness to one side and finds the pathos in the character, (like hitting the bottle and throwing up in the sink), that she's at her best. The problem is she's the only interesting character in the film (and it's not because of the script which doesn't do anybody any favours). Grint, on the other hand, isn't just unhappy; he's a bit of a bore as well while Linney's starched bitch is completely one-dimensional. (Still, she's got the English accent off pat). The best that can be said for it is that it's mildly enjoyable - with the emphasis on the mildly.\n",
      "0 1\n"
     ]
    }
   ],
   "source": [
    "preds, _ = new_model.predict(list(map(process, dataset['test']['text'])))\n",
    "test_preds = []\n",
    "for pred in preds:\n",
    "    if pred == ['__label__negative']:\n",
    "        test_preds.append(0)\n",
    "    else:\n",
    "        test_preds.append(1)\n",
    "\n",
    "test_targets = dataset['test']['label']\n",
    "\n",
    "count = 0\n",
    "examples = ['','']\n",
    "labels = [-1, -1]\n",
    "true_labels = [-1, -1]\n",
    "\n",
    "for i in range(len(test_targets)):\n",
    "    if count == 2:\n",
    "        break\n",
    "    if test_preds[i] != test_targets[i]:\n",
    "        examples[count] = dataset['test'][\"text\"][i]\n",
    "        labels[count] = test_preds[i]\n",
    "        true_labels[count] = test_targets[i]\n",
    "        count += 1;\n",
    "print(examples[0])\n",
    "print(true_labels[0], int(labels[0]))\n",
    "\n",
    "print(examples[1])\n",
    "print(true_labels[1], int(labels[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac69c6f3",
   "metadata": {},
   "source": [
    "The first one seems to be wrongly classified because of the phrasing of some sentance (If you haven't enjoyed a Van Damme movie since bloodsport, you probably will not like this movie.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb34c08",
   "metadata": {},
   "source": [
    "The second one is a positive review but emphasizing on the bad aspects of the movie."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0398be",
   "metadata": {},
   "source": [
    "### Why is it likely that the attributes minn and maxn are at 0 after an hyperparameter search on our data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3741202b",
   "metadata": {},
   "source": [
    "The minn and maxn parameters are used in the FastText library for character n-gram embeddings. \n",
    "Since english has a simple morphology, it may be optimal to set minn and maxn to 0. Moreover, our classification is strongly affected by the meaning of one word which can be positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7977e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('train.txt')\n",
    "os.remove('test.txt')\n",
    "os.remove('valid.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
